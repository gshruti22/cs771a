{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgZtSbK8eI_f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "tS7HiEk_dH_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "qw66wpb9eahF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df1.copy()"
      ],
      "metadata": {
        "id": "dLfG2iYE-AkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGMghG3Jf0t3",
        "outputId": "5424128e-3d45-4b48-a29d-41d4692d9c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(14990,inplace=True)"
      ],
      "metadata": {
        "id": "U9CWzTwCq55j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['o3op1', 'o3op2', 'no2op1', 'no2op2']]\n",
        "y = df[['OZONE', 'NO2']]"
      ],
      "metadata": {
        "id": "alZwFRAAdH1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "M8lFvl8bdp2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1=df['OZONE']\n",
        "y2=df['NO2']"
      ],
      "metadata": {
        "id": "973weU8KgtPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop( [ \"OZONE\",\"NO2\"], axis = \"columns\",inplace=True )"
      ],
      "metadata": {
        "id": "uRI0GMQtg0Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "mCy-kgmJg2DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error"
      ],
      "metadata": {
        "id": "skL8GSe51Da3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ridge"
      ],
      "metadata": {
        "id": "HEA8-q5r2IwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model"
      ],
      "metadata": {
        "id": "WNPQnVEtrqDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13))"
      ],
      "metadata": {
        "id": "DGUF2yBRrswQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "jpSVXSOhg2Kl",
        "outputId": "42685e5e-4711-456d-f450-5113485b7571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RidgeCV(alphas=array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01,\n",
              "       1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06]))"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeCV(alphas=array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01,\n",
              "       1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06]))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeCV</label><div class=\"sk-toggleable__content\"><pre>RidgeCV(alphas=array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01,\n",
              "       1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06]))</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytr1=reg.predict(X_test)"
      ],
      "metadata": {
        "id": "5map0eKl1Gyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_error(y_test, ytr1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zky_M6Ty00ly",
        "outputId": "5723486f-0979-4fb1-d329-648ce8f2ae4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.142715466687072"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lasso"
      ],
      "metadata": {
        "id": "_AbYm-gq2LYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg1 = linear_model.Lasso(alpha=0.5)"
      ],
      "metadata": {
        "id": "Y2M74k541iKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg1.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "Tg_VoiuB1iOM",
        "outputId": "29cde569-b2ba-4cb5-fc5d-0068f7ac1f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.942e+03, tolerance: 5.623e+02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.604e+03, tolerance: 1.848e+02\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso(alpha=0.5)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.5)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytr11=reg1.predict(X_test)"
      ],
      "metadata": {
        "id": "fielGFS12VJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_error(y_test, ytr11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5dIa1tF2ZE2",
        "outputId": "482e0df2-caec-4d4e-87cd-5d2b80bb263f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.180847168897229"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3DJb33DffvqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM"
      ],
      "metadata": {
        "id": "jGE54ym02fk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVR"
      ],
      "metadata": {
        "id": "nPYU9Yqp2abE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg2=LinearSVR(epsilon=0.1)\n",
        "reg2.fit(X_train, y_train['OZONE'])\n",
        "ytr12=reg2.predict(X_test)\n",
        "mean_absolute_error(y_test['OZONE'], ytr12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXThVzwR2qV8",
        "outputId": "e53d4028-73e7-40a7-9bca-ba10e8341be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.0725353863169005"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg3=LinearSVR(epsilon=0.1)\n",
        "reg3.fit(X_train, y_train['NO2'])\n",
        "ytr13=reg3.predict(X_test)\n",
        "mean_absolute_error(y_test['NO2'], ytr13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8RIRgHkfmDE",
        "outputId": "866318e2-5e76-4855-b744-f9d1bf682334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.9195406392341035"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Ridge"
      ],
      "metadata": {
        "id": "olj3ttpf2qfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg2=LinearSVR(epsilon=0.1)\n",
        "reg2.fit(X_train, y_train['OZONE'])\n",
        "ytr12=reg2.predict(X_test)\n",
        "mean_absolute_error(y_test['OZONE'], ytr12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "rjMBrs102qq9",
        "outputId": "53f1c88f-b256-4d39-d36c-f1d36f26a933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-a61bca6d461c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreg3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBayesianRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreg3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mytr13\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     )\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0mestimator_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_estimator_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1203\u001b[0m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (15999, 2) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg3=LinearSVR(epsilon=0.1)\n",
        "reg3.fit(X_train, y_train['NO2'])\n",
        "ytr13=reg3.predict(X_test)\n",
        "mean_absolute_error(y_test['NO2'], ytr13)"
      ],
      "metadata": {
        "id": "izt77tZnf4gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IzwPAiTr2qtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tvlSUCoe-Slr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alternative"
      ],
      "metadata": {
        "id": "CszeyYBLgkLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "X = df[['no2op1', 'no2op2', 'o3op1', 'o3op2']]\n",
        "y_o3 = df['OZONE']\n",
        "y_no2 = df['NO2']\n",
        "\n",
        "# Split df into train and test sets\n",
        "X_train, X_test, y_o3_train, y_o3_test, y_no2_train, y_no2_test = train_test_split(X, y_o3, y_no2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train linear regression\n",
        "reg = LinearRegression().fit(X_train, y_o3_train)\n",
        "y_o3_pred_reg = reg.predict(X_test)\n",
        "\n",
        "# Train lasso regression\n",
        "lasso = Lasso(alpha=0.1).fit(X_train, y_o3_train)\n",
        "y_o3_pred_lasso = lasso.predict(X_test)\n",
        "\n",
        "# Train ridge regression\n",
        "ridge = Ridge(alpha=0.1).fit(X_train, y_o3_train)\n",
        "y_o3_pred_ridge = ridge.predict(X_test)\n",
        "\n",
        "# Train linear SVM\n",
        "svm = LinearSVR(epsilon=0.01, random_state=42).fit(X_train, y_o3_train)\n",
        "y_o3_pred_svm = svm.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluate models for O3 prediction\n",
        "print(\"Linear Regression:\")\n",
        "print(\"Mean absolute error: %.2f\" % mean_absolute_error(y_o3_test, y_o3_pred_reg))\n",
        "print(\"Coefficient of determination: %.2f\" % r2_score(y_o3_test, y_o3_pred_reg))\n",
        "print()\n",
        "print(\"Lasso Regression:\")\n",
        "print(\"Mean absolute error: %.2f\" % mean_absolute_error(y_o3_test, y_o3_pred_lasso))\n",
        "print(\"Coefficient of determination: %.2f\" % r2_score(y_o3_test, y_o3_pred_lasso))\n",
        "print()\n",
        "print(\"Ridge Regression:\")\n",
        "print(\"Mean absolute error: %.2f\" % mean_absolute_error(y_o3_test, y_o3_pred_ridge))\n",
        "print(\"Coefficient of determination: %.2f\" % r2_score(y_o3_test, y_o3_pred_ridge))\n",
        "print()\n",
        "print(\"Linear SVM:\")\n",
        "print(\"Mean absolute error: %.2f\" % mean_absolute_error(y_o3_test, y_o3_pred_svm))\n",
        "print(\"Coefficient of determination: %.2f\" % r2_score(y_o3_test, y_o3_pred_svm))\n",
        "print()\n"
      ],
      "metadata": {
        "id": "6qFOWnmlgjHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l3hAuhhfhVb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "X = df[['no2op1', 'no2op2', 'o3op1', 'o3op2']]\n",
        "y_o3 = df['OZONE']\n",
        "y_no2 = df['NO2']\n",
        "\n",
        "# Split df into train and test sets\n",
        "X_train, X_test, y_o3_train, y_o3_test, y_no2_train, y_no2_test = train_test_split(X, y_o3, y_no2, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Define models\n",
        "models = [\n",
        "    LinearRegression(),\n",
        "    Ridge(alpha=0.1),\n",
        "    Lasso(alpha=0.1),\n",
        "    ElasticNet(alpha=0.1),\n",
        "    LinearSVR(epsilon=1.5)\n",
        "]\n",
        "\n",
        "# Train models and compute Mean Absolute Error on test set for both O3 and NO2\n",
        "results = []\n",
        "for model in models:\n",
        "    model_name = type(model).__name__\n",
        "    model.fit(X_train, y_o3_train)\n",
        "    o3_mae = mean_absolute_error(y_o3_test, model.predict(X_test))\n",
        "    model.fit(X_train, y_no2_train)\n",
        "    no2_mae = mean_absolute_error(y_no2_test, model.predict(X_test))\n",
        "    results.append((model_name, o3_mae, no2_mae))\n",
        "\n",
        "# Print results\n",
        "print(\"Model\\t\\tO3 MAE\\tNO2 MAE\")\n",
        "for model_name, o3_mae, no2_mae in results:\n",
        "    print(f\"{model_name:12}\\t{o3_mae:.2f}\\t{no2_mae:.2f}\")\n",
        "\n",
        "\n",
        "# # Train linear regression\n",
        "# reg = LinearRegression().fit(X_train, y_no2_train)\n",
        "# y_no2_pred_reg = reg.predict(X_test)\n",
        "\n",
        "# # Train lasso regression\n",
        "# lasso = Lasso(alpha=0.1).fit(X_train, y_no2_train)\n",
        "# y_no2_pred_lasso = lasso.predict(X_test)\n",
        "\n",
        "# # Train ridge regression\n",
        "# ridge = Ridge(alpha=0.1).fit(X_train, y_no2_train)\n",
        "# y_no2_pred_ridge = ridge.predict(X_test)\n",
        "\n",
        "# # Train linear SVM\n",
        "# svm = LinearSVR(epsilon=0.01, random_state=42).fit(X_train, y_no2_train)\n",
        "# y_no2_pred_svm = svm.predict(X_test)\n",
        "\n",
        "\n",
        "# # Evaluate models for O3 prediction\n",
        "# print(\"Linear Regression:\")\n",
        "# print(\"Mean absolute error: %.2f\" % mean_absolute_error(y_o3_test, y_o3_pred_reg))\n",
        "# print(\"Coefficient of determination: %.2f\" % r2_score(y_o3_test, y_o3_pred_reg))\n",
        "# print()\n",
        "# print(\"Lasso Regression:\")\n",
        "# print(\"Mean absolute error: %.2f\" % mean_absolute_error(y_o3_test, y_o3_pred_lasso))\n",
        "# print(\"Coefficient of determination: %.2f\" % r2_score(y_o3_test, y_o3_pred_lasso))\n",
        "# print()\n",
        "# print(\"Ridge Regression:\")\n",
        "# print(\"Mean absolute error: %.2f\" % mean_absolute_error(y_o3_test, y_o3_pred_ridge))\n",
        "# print(\"Coefficient of determination: %.2f\" % r2_score(y_o3_test, y_o3_pred_ridge))\n",
        "# print()\n",
        "# print(\"Linear SVM:\")\n",
        "# print(\"Mean absolute error: %.2f\" % mean_absolute_error(y_o3_test, y_o3_pred_svm))\n",
        "# print(\"Coefficient of determination: %.2f\" % r2_score(y_o3_test, y_o3_pred_svm))\n",
        "# print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x3VtypZgjK3",
        "outputId": "e20bbf3c-25fb-4982-c6ee-4668a9492930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.564e+03, tolerance: 5.623e+02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+05, tolerance: 1.848e+02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e+03, tolerance: 5.623e+02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.190e+05, tolerance: 1.848e+02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model\t\tO3 MAE\tNO2 MAE\n",
            "LinearRegression\t5.58\t6.70\n",
            "Ridge       \t5.58\t6.70\n",
            "Lasso       \t5.58\t6.70\n",
            "ElasticNet  \t5.58\t6.70\n",
            "LinearSVR   \t5.91\t10.93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, HuberRegressor, SGDRegressor, PassiveAggressiveRegressor, RANSACRegressor, BayesianRidge\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import pandas as pd\n",
        "import pickle\n",
        "# Load data\n",
        "data = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Split into features and labels\n",
        "X = data[['no2op1', 'no2op2', 'o3op1', 'o3op2']]\n",
        "y_o3 = data['OZONE']\n",
        "y_no2 = data['NO2']\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_o3_train, y_o3_test, y_no2_train, y_no2_test = train_test_split(\n",
        "    X, y_o3, y_no2, test_size=0.3, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "clf=LinearSVR(C=10,epsilon=1)\n",
        "clf.fit(X_train_scaled, y_o3_train)\n",
        "\n",
        "pickle.dump(clf,open(\"part11.pkl\",'wb'))\n",
        "o3_mae = mean_absolute_error(y_o3_test, clf.predict(X_test_scaled))\n",
        "clf.fit(X_train_scaled, y_no2_train)\n",
        "pickle.dump(clf,open(\"part12.pkl\",'wb'))\n",
        "no2_mae = mean_absolute_error(y_no2_test, clf.predict(X_test_scaled))"
      ],
      "metadata": {
        "id": "b6C5DT74gjPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf=LinearSVR(C=10,epsilon=1)"
      ],
      "metadata": {
        "id": "-wn_UliIyQkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QNmUrnlO2WNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train_scaled, y_o3_train)\n",
        "\n",
        "pickle.dump(clf,open(\"part11.pkl\",'wb'))\n",
        "o3_mae = mean_absolute_error(y_o3_test, clf.predict(X_test_scaled))\n",
        "clf.fit(X_train_scaled, y_no2_train)\n",
        "pickle.dump(clf,open(\"part12.pkl\",'wb'))\n",
        "no2_mae = mean_absolute_error(y_no2_test, clf.predict(X_test_scaled))"
      ],
      "metadata": {
        "id": "Ocv3FW5Oy7X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, HuberRegressor, SGDRegressor, PassiveAggressiveRegressor, RANSACRegressor, BayesianRidge\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import pandas as pd\n",
        "import pickle\n",
        "# Load data\n",
        "data = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Split into features and labels\n",
        "X = data[['no2op1', 'no2op2', 'o3op1', 'o3op2']]\n",
        "y_o3 = data['OZONE']\n",
        "y_no2 = data['NO2']\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_o3_train, y_o3_test, y_no2_train, y_no2_test = train_test_split(\n",
        "    X, y_o3, y_no2, test_size=0.3, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define models and hyperparameters\n",
        "models = [\n",
        "    LinearRegression(),\n",
        "    Ridge(),\n",
        "    Lasso(),\n",
        "    ElasticNet(),\n",
        "    LinearSVR(),\n",
        "    HuberRegressor(epsilon=1.35),\n",
        "    SGDRegressor(alpha=0.0001, max_iter=1000),\n",
        "    PassiveAggressiveRegressor(C=1.0, max_iter=1000),\n",
        "    RANSACRegressor(),\n",
        "    BayesianRidge()\n",
        "]\n",
        "\n",
        "params = [\n",
        "    {},\n",
        "    {'alpha': [0.1, 0.5, 1.0]},\n",
        "    {'alpha': [0.1, 0.5, 1.0]},\n",
        "    {'alpha': [0.1, 0.5, 1.0], 'l1_ratio': [0.25, 0.5, 0.75]},\n",
        "    {'C': [0.1, 1.0, 10.0], 'epsilon': [0.5, 1.0, 1.5]},\n",
        "    {},\n",
        "    {},\n",
        "    {},\n",
        "    {},\n",
        "    {}\n",
        "]\n",
        "\n",
        "# Train models and compute Mean Absolute Error on test set for both O3 and NO2\n",
        "results = []\n",
        "for i, model in enumerate(models):\n",
        "    model_name = type(model).__name__\n",
        "    clf = GridSearchCV(model, params[i], scoring='neg_mean_absolute_error')\n",
        "    clf.fit(X_train_scaled, y_o3_train)\n",
        "    print(clf.best_params_)\n",
        "    pickle.dump\n",
        "    o3_mae = mean_absolute_error(y_o3_test, clf.predict(X_test_scaled))\n",
        "    clf.fit(X_train_scaled, y_no2_train)\n",
        "    no2_mae = mean_absolute_error(y_no2_test, clf.predict(X_test_scaled))\n",
        "    results.append((model_name, o3_mae, no2_mae))\n",
        "\n",
        "# Print results\n",
        "print(\"Model\\t\\tO3 MAE\\tNO2 MAE\")\n",
        "for model_name, o3_mae, no2_mae in results:\n",
        "    print(f\"{model_name:12}\\t{o3_mae:.2f}\\t{no2_mae:.2f}\")\n"
      ],
      "metadata": {
        "id": "zOmgaOC-iOLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sax-F4_Nu5ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sGkZPSL_iON5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2"
      ],
      "metadata": {
        "id": "E-iImx_M-Sxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "k4_rjJdJ3h05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Calculate mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Random Forest MAE:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icx5MjgNgjVw",
        "outputId": "740fa4f4-6bf2-467b-c51d-2767861c814c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest MAE: 3.332456452075302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "CTZfYs-4z2Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bw1kM5DR0mgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the range of hyperparameters\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Create a grid search object\n",
        "rf = RandomForestRegressor()\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
        "\n",
        "# Fit the grid search object to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6WUwken03M_",
        "outputId": "0dd05dd7-2129-451d-d485-907787888d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 20, 'min_samples_leaf': 1, 'n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKbsV2rR1V-Y",
        "outputId": "1fad30a3-51f2-4fc0-9f25-263827726454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE on test set: 3.3225346217035723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "93yu3l6X0Tie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Preprocessing\n",
        "X = df[['temp', 'humidity', 'no2op1', 'no2op2', 'o3op1', 'o3op2']]\n",
        "y = df[['OZONE', 'NO2']]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "import pickle\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Splitting data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "rf = RandomForestRegressor(n_estimators=200, max_depth=20, min_samples_leaf=1)\n",
        "\n",
        "# Fit the model on the entire training set\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf.predict(X_test)\n",
        "pickle.dump(rf,open(\"part2.pkl\",'wb'))\n",
        "# Calculate and print the MAE on the test set\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"MAE on test set:\", mae)"
      ],
      "metadata": {
        "id": "GTviskOp1Yeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nkrGSJ2B1Ygw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Preprocessing\n",
        "X = df[['temp', 'humidity', 'no2op1', 'no2op2', 'o3op1', 'o3op2']]\n",
        "y = df[['OZONE', 'NO2']]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predicting\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"MAE: {:.2f}\".format(mae))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CrcXDeP0mik",
        "outputId": "857c4c1e-24b3-49c6-a7d3-4add7ab09107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 3.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X9wfKiIL3n0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FAjp4nFT3n8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "PnTDVAcJ3o4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('train.csv')\n",
        "\n",
        "# Select relevant features\n",
        "features = ['temp', 'humidity', 'no2op1', 'no2op2', 'o3op1', 'o3op2']\n",
        "\n",
        "# Split into features and target\n",
        "X = data[features]\n",
        "y = data[['OZONE', 'NO2']]\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Define the model\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'learning_rate': [0.001, 0.01, 0.1, 0.3],\n",
        "    'gamma': [0, 0.1, 0.3, 0.5, 1],\n",
        "    'subsample': [0.5, 0.7, 0.9, 1],\n",
        "    'colsample_bytree': [0.5, 0.7, 0.9, 1],\n",
        "    'min_child_weight': [1, 3, 5, 7],\n",
        "    'reg_alpha': [0, 0.1, 0.5, 1],\n",
        "    'reg_lambda': [0, 0.1, 0.5, 1]\n",
        "}\n",
        "\n",
        "# Perform random search\n",
        "xgb_random = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist,\n",
        "                                scoring='neg_mean_absolute_error', n_iter=100, cv=3,\n",
        "                                verbose=3, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Fit the random search model\n",
        "xgb_random.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print best hyperparameters\n",
        "print(xgb_random.best_params_)\n",
        "\n",
        "\n",
        "# Train the model with best hyperparameters\n",
        "best_xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1,\n",
        "                                  **xgb_random.best_params_)\n",
        "best_xgb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on test set\n",
        "y_pred = best_xgb_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print('MAE:', mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpRmJGnW3n-2",
        "outputId": "2d36aa59-0e88-46bb-c89c-dbf67ed6da95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
            "{'subsample': 0.7, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'n_estimators': 150, 'min_child_weight': 5, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.9}\n",
            "MAE: 3.4308775214530094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yl78BLgE3oID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2fDWdSd0m9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LightGBM"
      ],
      "metadata": {
        "id": "4U9bNuWi6zpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# define the LightGBM model\n",
        "lgb_model = lgb.LGBMRegressor(boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=100)\n",
        "\n",
        "# hyperparameter tuning with GridSearchCV\n",
        "param_grid = {\n",
        "    'num_leaves': [31, 50, 100],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [-1, 5, 10]\n",
        "}\n",
        "grid_search = GridSearchCV(estimator=lgb_model, param_grid=param_grid, cv=5, n_jobs=-1, scoring='neg_mean_absolute_error')\n",
        "grid_search.fit(X_train, y_train['OZONE'])\n",
        "\n",
        "# print best hyperparameters\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# train the model with best hyperparameters\n",
        "best_lgb_model = lgb.LGBMRegressor(boosting_type='gbdt', **grid_search.best_params_)\n",
        "best_lgb_model.fit(X_train, y_train['OZONE'])\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred = best_lgb_model.predict(X_test)\n",
        "\n",
        "# calculate mean absolute error\n",
        "mae = mean_absolute_error(y_test['OZONE'], y_pred)\n",
        "print(\"Mean absolute error:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A25lflS66y8T",
        "outputId": "e0ff595b-7779-41fb-a577-ae369f4ecfbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 100}\n",
            "Mean absolute error: 3.9266288707003385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ms_DCofs69Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "slQrOa2Y69Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensemble"
      ],
      "metadata": {
        "id": "GrljaWEd886F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Separate the target variables\n",
        "y = data[[\"OZONE\", \"NO2\"]]\n",
        "X = data.drop([\"OZONE\", \"NO2\", \"Time\"], axis=1) # Dropping the Time column\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Define the base models\n",
        "models = [\n",
        "    make_pipeline(StandardScaler(), LinearRegression()),\n",
        "    make_pipeline(StandardScaler(), RidgeCV(cv=5)),\n",
        "    make_pipeline(StandardScaler(), LassoCV(cv=5)),\n",
        "    make_pipeline(StandardScaler(), SVR(kernel='linear')),\n",
        "    RandomForestRegressor(n_estimators=100, random_state=0),\n",
        "]\n",
        "\n",
        "# Define the meta-model\n",
        "meta_model = LinearRegression()\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 5\n",
        "\n",
        "# Define the indices for splitting the data into training and testing sets\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Define arrays to store the predictions and targets for the training set\n",
        "X_meta_train = np.zeros((len(X_train), len(models)*2))\n",
        "y_meta_train = y_train.values.copy()\n",
        "\n",
        "# Train the base models on the training set using cross-validation\n",
        "for i, model in enumerate(models):\n",
        "    for train_index, val_index in kf.split(X_train):\n",
        "        X_train_kf, X_val_kf = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "        y_train_kf, y_val_kf = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "        # Train the model on the training set\n",
        "        model.fit(X_train_kf, y_train_kf)\n",
        "\n",
        "        # Predict on the validation set\n",
        "        y_pred_val = model.predict(X_val_kf)\n",
        "\n",
        "        # Store the predictions for the validation set\n",
        "        X_meta_train[val_index, i] = y_pred_val[:, 0]\n",
        "        X_meta_train[val_index, i+len(models)] = y_pred_val[:, 1]\n",
        "\n",
        "# Train the meta-model on the training set\n",
        "meta_model.fit(X_meta_train, y_meta_train)\n",
        "\n",
        "# Define arrays to store the predictions and targets for the testing set\n",
        "X_meta_test = np.zeros((len(X_test), len(models)*2))\n",
        "y_meta_test = y_test.values.copy()\n",
        "\n",
        "# Predict on the testing set using the base models\n",
        "for i, model in enumerate(models):\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    # Store the predictions for the testing set\n",
        "    X_meta_test[:, i] = y_pred_test[:, 0]\n",
        "    X_meta_test[:, i+len(models)] = y_pred_test[:, 1]\n",
        "\n",
        "\n",
        "y_pred_test = meta_model.predict(X_meta_test)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred_test)\n",
        "print(\"Mean absolute error: \", mae)\n"
      ],
      "metadata": {
        "id": "P2ht1QuF86Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, MultiTaskLassoCV\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Separate the target variables\n",
        "y = data[[\"OZONE\", \"NO2\"]]\n",
        "X = data.drop([\"OZONE\", \"NO2\", \"Time\"], axis=1) # Dropping the Time column\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Define the base models\n",
        "models = [\n",
        "    make_pipeline(StandardScaler(), LinearRegression()),\n",
        "    make_pipeline(StandardScaler(), RidgeCV(cv=5)),\n",
        "    make_pipeline(StandardScaler(), MultiTaskLassoCV(cv=5)),\n",
        "    # make_pipeline(StandardScaler(), SVR(kernel='linear')),\n",
        "    RandomForestRegressor(n_estimators=100, random_state=0),\n",
        "]\n",
        "\n",
        "# Define the meta-model\n",
        "meta_model = LinearRegression()\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 5\n",
        "\n",
        "# Define the indices for splitting the data into training and testing sets\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Define arrays to store the predictions and targets for the training set\n",
        "X_meta_train = np.zeros((len(X_train), len(models)*2))\n",
        "y_meta_train = y_train.values.copy()\n",
        "\n",
        "# Train the base models on the training set using cross-validation\n",
        "for i, model in enumerate(models):\n",
        "    for train_index, val_index in kf.split(X_train):\n",
        "        X_train_kf, X_val_kf = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "        y_train_kf, y_val_kf = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "        # Train the model on the training set\n",
        "        model.fit(X_train_kf, y_train_kf)\n",
        "\n",
        "        # Predict on the validation set\n",
        "        y_pred_val = model.predict(X_val_kf)\n",
        "\n",
        "        # Store the predictions for the validation set\n",
        "        X_meta_train[val_index, i] = y_pred_val[:, 0]\n",
        "        X_meta_train[val_index, i+len(models)] = y_pred_val[:, 1]\n",
        "\n",
        "# Train the meta-model on the training set\n",
        "meta_model.fit(X_meta_train, y_meta_train)\n",
        "\n",
        "# Define arrays to store the predictions and targets for the testing set\n",
        "X_meta_test = np.zeros((len(X_test), len(models)*2))\n",
        "y_meta_test = y_test.values.copy()\n",
        "\n",
        "# Predict on the testing set using the base models\n",
        "for i, model in enumerate(models):\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    # Store the predictions for the testing set\n",
        "    X_meta_test[:, i] = y_pred_test[:, 0]\n",
        "    X_meta_test[:, i+len(models)] = y_pred_test[:, 1]\n",
        "\n",
        "# Predict on the testing set using the meta-model\n",
        "y_pred_meta = meta_model.predict(X_meta_test)\n",
        "\n",
        "# Compute the mean absolute error of the meta-model predictions\n",
        "mae = mean_absolute_error(y_meta_test, y_pred_meta)\n",
        "print(\"Mean absolute error: {:.2f}\".format(mae))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX1fRfxI86Ju",
        "outputId": "586dc8c3-4ba3-4dde-ca33-e48323f1ba19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:2418: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2789.359739304986, tolerance: 609.7370220101244\n",
            "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:2418: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2808.711838771822, tolerance: 606.8375387717102\n",
            "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:2418: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2677.2656871171203, tolerance: 617.348625945103\n",
            "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:2418: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2776.9368766306434, tolerance: 603.1145329366808\n",
            "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:2418: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2813.453417076962, tolerance: 591.16710321118\n",
            "  ) = cd_fast.enet_coordinate_descent_multi_task(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute error: 3.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZZLtAsTA-ezV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UkQ3ceeJ-e1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9YC3XEmt-e4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DNN"
      ],
      "metadata": {
        "id": "NGcup2Ju3lvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the df2\n",
        "df2 = pd.read_csv('train.csv')\n",
        "\n",
        "df2['Time'] = pd.to_datetime(df2['Time']).astype(int) / 10**9\n",
        "\n",
        "# Split the df2 into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df2.drop(['Time','OZONE', 'NO2'], axis=1), df2[['OZONE', 'NO2']],\n",
        "    test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the DNN model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(2))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.001), metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs=100,\n",
        "                    batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test df2\n",
        "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test MAE:', test_mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_XALj14yIOq",
        "outputId": "b8c24ef7-8951-446e-a038-dbaf135da903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400/400 [==============================] - 2s 3ms/step - loss: 489.5409 - mae: 15.2395 - val_loss: 182.0329 - val_mae: 9.1899\n",
            "Epoch 2/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 217.8058 - mae: 10.4885 - val_loss: 160.6712 - val_mae: 8.5245\n",
            "Epoch 3/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 182.7085 - mae: 9.5523 - val_loss: 128.3840 - val_mae: 7.7019\n",
            "Epoch 4/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 156.6001 - mae: 8.9073 - val_loss: 113.8872 - val_mae: 7.2774\n",
            "Epoch 5/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 141.7115 - mae: 8.5119 - val_loss: 102.3785 - val_mae: 6.9012\n",
            "Epoch 6/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 131.4662 - mae: 8.1486 - val_loss: 97.6822 - val_mae: 6.5701\n",
            "Epoch 7/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 120.9219 - mae: 7.8217 - val_loss: 87.2089 - val_mae: 6.4385\n",
            "Epoch 8/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 111.8733 - mae: 7.5374 - val_loss: 72.9352 - val_mae: 6.0541\n",
            "Epoch 9/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 105.3383 - mae: 7.3104 - val_loss: 75.7306 - val_mae: 5.8162\n",
            "Epoch 10/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 99.8163 - mae: 7.1002 - val_loss: 63.4578 - val_mae: 5.5545\n",
            "Epoch 11/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 97.4893 - mae: 6.9752 - val_loss: 76.5436 - val_mae: 5.8518\n",
            "Epoch 12/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 94.5507 - mae: 6.8679 - val_loss: 78.0348 - val_mae: 5.8984\n",
            "Epoch 13/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 93.5246 - mae: 6.8659 - val_loss: 61.3177 - val_mae: 5.4536\n",
            "Epoch 14/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 90.8091 - mae: 6.7121 - val_loss: 60.5775 - val_mae: 5.4741\n",
            "Epoch 15/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 90.4037 - mae: 6.7187 - val_loss: 55.8574 - val_mae: 5.3715\n",
            "Epoch 16/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 88.8411 - mae: 6.6374 - val_loss: 57.1708 - val_mae: 5.2994\n",
            "Epoch 17/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 89.5001 - mae: 6.6665 - val_loss: 62.2399 - val_mae: 5.4020\n",
            "Epoch 18/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 89.0295 - mae: 6.6565 - val_loss: 56.3836 - val_mae: 5.4214\n",
            "Epoch 19/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 88.2799 - mae: 6.6374 - val_loss: 62.1692 - val_mae: 5.3809\n",
            "Epoch 20/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 85.3059 - mae: 6.5346 - val_loss: 59.3628 - val_mae: 5.4636\n",
            "Epoch 21/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 87.3297 - mae: 6.6112 - val_loss: 57.1747 - val_mae: 5.2708\n",
            "Epoch 22/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 88.0395 - mae: 6.5966 - val_loss: 57.5234 - val_mae: 5.4195\n",
            "Epoch 23/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 87.8846 - mae: 6.6013 - val_loss: 58.9296 - val_mae: 5.3371\n",
            "Epoch 24/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 85.6772 - mae: 6.5231 - val_loss: 64.6825 - val_mae: 5.5502\n",
            "Epoch 25/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 82.4434 - mae: 6.4109 - val_loss: 60.9691 - val_mae: 5.3989\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 66.3539 - mae: 5.5643\n",
            "Test loss: 66.35394287109375\n",
            "Test MAE: 5.564268589019775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NT2YASSYyIQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "N97pjEtE-TtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop(14990,inplace=True)"
      ],
      "metadata": {
        "id": "U09lmDew-VVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NhyMuPmt-myu",
        "outputId": "7f88030f-755a-41f9-c005-05b928d98741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Time   OZONE     NO2  temp  humidity  no2op1  no2op2  \\\n",
              "0      2019-03-27 13:01:00  77.590   6.881  36.2      38.9   199.0   200.0   \n",
              "1      2019-03-27 13:03:00  78.710  11.057  36.3      37.7   196.0   200.0   \n",
              "2      2019-03-27 13:04:00  78.850   8.596  36.7      38.0   195.0   199.0   \n",
              "3      2019-03-27 13:07:00  79.270   7.248  37.0      37.5   193.0   198.0   \n",
              "4      2019-03-27 13:08:00  80.010   8.638  36.8      36.8   191.0   198.0   \n",
              "...                    ...     ...     ...   ...       ...     ...     ...   \n",
              "19995  2019-05-06 10:19:00  33.970   3.371  27.7      99.9   162.0   164.0   \n",
              "19996  2019-05-06 10:22:00  33.073   2.883  27.4      99.9   170.0   171.0   \n",
              "19997  2019-05-06 10:23:00  32.313   2.578  27.5      99.9   165.0   168.0   \n",
              "19998  2019-05-06 10:24:00  33.367   2.114  27.4      99.9   163.0   166.0   \n",
              "19999  2019-05-06 10:29:00  32.213   2.479  27.2      99.9   167.0   168.0   \n",
              "\n",
              "       o3op1  o3op2  \n",
              "0      240.0  197.0  \n",
              "1      237.0  196.0  \n",
              "2      235.0  196.0  \n",
              "3      233.0  195.0  \n",
              "4      231.0  195.0  \n",
              "...      ...    ...  \n",
              "19995  175.0  161.0  \n",
              "19996  180.0  168.0  \n",
              "19997  175.0  164.0  \n",
              "19998  174.0  161.0  \n",
              "19999  177.0  162.0  \n",
              "\n",
              "[19999 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acab8aee-98ef-4656-a20b-f35789ba2a77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>OZONE</th>\n",
              "      <th>NO2</th>\n",
              "      <th>temp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>no2op1</th>\n",
              "      <th>no2op2</th>\n",
              "      <th>o3op1</th>\n",
              "      <th>o3op2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-03-27 13:01:00</td>\n",
              "      <td>77.590</td>\n",
              "      <td>6.881</td>\n",
              "      <td>36.2</td>\n",
              "      <td>38.9</td>\n",
              "      <td>199.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>197.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-03-27 13:03:00</td>\n",
              "      <td>78.710</td>\n",
              "      <td>11.057</td>\n",
              "      <td>36.3</td>\n",
              "      <td>37.7</td>\n",
              "      <td>196.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>196.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-03-27 13:04:00</td>\n",
              "      <td>78.850</td>\n",
              "      <td>8.596</td>\n",
              "      <td>36.7</td>\n",
              "      <td>38.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>199.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>196.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-03-27 13:07:00</td>\n",
              "      <td>79.270</td>\n",
              "      <td>7.248</td>\n",
              "      <td>37.0</td>\n",
              "      <td>37.5</td>\n",
              "      <td>193.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>195.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-03-27 13:08:00</td>\n",
              "      <td>80.010</td>\n",
              "      <td>8.638</td>\n",
              "      <td>36.8</td>\n",
              "      <td>36.8</td>\n",
              "      <td>191.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>195.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>2019-05-06 10:19:00</td>\n",
              "      <td>33.970</td>\n",
              "      <td>3.371</td>\n",
              "      <td>27.7</td>\n",
              "      <td>99.9</td>\n",
              "      <td>162.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>161.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>2019-05-06 10:22:00</td>\n",
              "      <td>33.073</td>\n",
              "      <td>2.883</td>\n",
              "      <td>27.4</td>\n",
              "      <td>99.9</td>\n",
              "      <td>170.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>168.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>2019-05-06 10:23:00</td>\n",
              "      <td>32.313</td>\n",
              "      <td>2.578</td>\n",
              "      <td>27.5</td>\n",
              "      <td>99.9</td>\n",
              "      <td>165.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>164.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>2019-05-06 10:24:00</td>\n",
              "      <td>33.367</td>\n",
              "      <td>2.114</td>\n",
              "      <td>27.4</td>\n",
              "      <td>99.9</td>\n",
              "      <td>163.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>161.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>2019-05-06 10:29:00</td>\n",
              "      <td>32.213</td>\n",
              "      <td>2.479</td>\n",
              "      <td>27.2</td>\n",
              "      <td>99.9</td>\n",
              "      <td>167.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>162.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19999 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acab8aee-98ef-4656-a20b-f35789ba2a77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acab8aee-98ef-4656-a20b-f35789ba2a77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acab8aee-98ef-4656-a20b-f35789ba2a77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HeksH9no-p7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P5ULctmp-p83"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}